


```markdown
# ğŸ§  Next Word Predictor

A full-stack Machine Learning application that predicts the **next word** in a given sentence using a deep learning model trained on Shakespeare's text.  
This project includes:

- ğŸ”„ Data preprocessing and sequence generation with TensorFlow
- ğŸ§  Model training using LSTM + Bidirectional RNN
- ğŸš€ FastAPI backend for real-time prediction
- ğŸ¨ Streamlit frontend for user interaction
```


## ğŸ§ª Model Architecture

- ğŸ”  Embedding Layer
- ğŸ” Bidirectional LSTM (150 units)
- ğŸ’§ Dropout (0.2)
- ğŸ” LSTM (100 units)
- ğŸ§® Dense Softmax output layer

Loss function: `categorical_crossentropy`  
Optimizer: `adam`



## ğŸ“¦ Installation

1. **Clone the repository:**

```bash
git clone https://github.com/yourusername/next_word_predictor.git
cd next_word_predictor
````

2. **Install the required packages:**

```bash
pip install -r requirements.txt
```

> Create `requirements.txt` with:

```txt
tensorflow
numpy
pickle-mixin
streamlit
fastapi
uvicorn
requests
```



## âš™ï¸ Usage

### 1. Train the Model

```bash
cd training
python preprocess.py     # Prepares X.npy, y.npy, tokenizer
python train.py          # Trains and saves the model
```

### 2. Start the FastAPI Backend

```bash
uvicorn api.app:app --reload
```

API will be live at: [http://127.0.0.1:8000/predict](http://127.0.0.1:8000/predict)

### 3. Run the Streamlit Frontend

In a new terminal:

```bash
streamlit run streamlit_app.py
```

Streamlit UI will open in the browser: [http://localhost:8501](http://localhost:8501)



## ğŸ“Œ Sample Input

> Input:

```
to be or not
```

> Output:

```
Predicted next word: to
```



## ğŸš€ Deployment Suggestions

* **API**: Deploy FastAPI backend on [Render](https://render.com) or [Railway](https://railway.app)
* **Frontend**: Deploy Streamlit app on [Streamlit Cloud](https://streamlit.io/cloud)
* **Storage**: Use AWS S3 or GitHub for storing model assets (`model.h5`, `tokenizer.pkl`)



## ğŸ“š Dataset

The dataset used is [Shakespeareâ€™s Complete Works](https://ocw.mit.edu/ans7870/6/6.005/s16/psets/ps1/shakespeare.txt), cleaned and tokenized for training.


## ğŸ¤ Contributing

Contributions are welcome! Please open an issue first to discuss your idea.





