
---

```markdown
# ğŸ§  Next Word Predictor

A full-stack Machine Learning application that predicts the **next word** in a given sentence using a deep learning model trained on Shakespeare's text.  
This project includes:

- ğŸ”„ Data preprocessing and sequence generation with TensorFlow
- ğŸ§  Model training using LSTM + Bidirectional RNN
- ğŸš€ FastAPI backend for real-time prediction
- ğŸ¨ Streamlit frontend for user interaction

---

## ğŸ“ Project Structure

```

next\_word\_predictor/
â”œâ”€â”€ api/                    # FastAPI backend
â”‚   â””â”€â”€ app.py              # API with POST /predict
â”œâ”€â”€ model/                  # Trained model & tokenizer
â”‚   â”œâ”€â”€ model.h5
â”‚   â”œâ”€â”€ tokenizer.pkl
â”‚   â”œâ”€â”€ X.npy
â”‚   â””â”€â”€ y.npy
â”œâ”€â”€ training/               # Training pipeline
â”‚   â”œâ”€â”€ preprocess.py       # Text preprocessing & dataset creation
â”‚   â””â”€â”€ train.py            # LSTM model training script
â”œâ”€â”€ predict.py              # Next word prediction logic
â”œâ”€â”€ streamlit\_app.py        # Frontend for interacting with the API
â”œâ”€â”€ data/
â”‚   â””â”€â”€ shakespeare.txt     # Raw dataset used for training
â””â”€â”€ README.md               # Project documentation

````

---

## ğŸ§ª Model Architecture

- ğŸ”  Embedding Layer
- ğŸ” Bidirectional LSTM (150 units)
- ğŸ’§ Dropout (0.2)
- ğŸ” LSTM (100 units)
- ğŸ§® Dense Softmax output layer

Loss function: `categorical_crossentropy`  
Optimizer: `adam`

---

## ğŸ“¦ Installation

1. **Clone the repository:**

```bash
git clone https://github.com/yourusername/next_word_predictor.git
cd next_word_predictor
````

2. **Install the required packages:**

```bash
pip install -r requirements.txt
```

> Create `requirements.txt` with:

```txt
tensorflow
numpy
pickle-mixin
streamlit
fastapi
uvicorn
requests
```

---

## âš™ï¸ Usage

### 1. Train the Model

```bash
cd training
python preprocess.py     # Prepares X.npy, y.npy, tokenizer
python train.py          # Trains and saves the model
```

### 2. Start the FastAPI Backend

```bash
uvicorn api.app:app --reload
```

API will be live at: [http://127.0.0.1:8000/predict](http://127.0.0.1:8000/predict)

### 3. Run the Streamlit Frontend

In a new terminal:

```bash
streamlit run streamlit_app.py
```

Streamlit UI will open in the browser: [http://localhost:8501](http://localhost:8501)

---

## ğŸ“Œ Sample Input

> Input:

```
to be or not
```

> Output:

```
Predicted next word: to
```

---

## ğŸš€ Deployment Suggestions

* **API**: Deploy FastAPI backend on [Render](https://render.com) or [Railway](https://railway.app)
* **Frontend**: Deploy Streamlit app on [Streamlit Cloud](https://streamlit.io/cloud)
* **Storage**: Use AWS S3 or GitHub for storing model assets (`model.h5`, `tokenizer.pkl`)

---

## ğŸ“š Dataset

The dataset used is [Shakespeareâ€™s Complete Works](https://ocw.mit.edu/ans7870/6/6.005/s16/psets/ps1/shakespeare.txt), cleaned and tokenized for training.

---

## ğŸ¤ Contributing

Contributions are welcome! Please open an issue first to discuss your idea.



---

